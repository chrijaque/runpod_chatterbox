import runpod
import time  
import torchaudio 
import os
import tempfile
import base64
import torch
import logging
import hashlib
from chatterbox.tts import ChatterboxTTS
from pathlib import Path
from datetime import datetime, timedelta
from google.cloud import storage
import numpy as np  # Added for MP3 conversion
from typing import Optional

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import the handler from the forked repository
try:
    from chatterbox.vc import ChatterboxVC
    FORKED_HANDLER_AVAILABLE = True
    logger.info("‚úÖ Successfully imported ChatterboxVC from forked repository")
except ImportError as e:
    FORKED_HANDLER_AVAILABLE = False
    logger.warning(f"‚ö†Ô∏è Could not import ChatterboxVC from forked repository: {e}")

model = None
forked_handler = None

# Local directory paths (use absolute paths for RunPod deployment)
VOICE_PROFILES_DIR = Path("/voice_profiles")
VOICE_SAMPLES_DIR = Path("/voice_samples") 
TEMP_VOICE_DIR = Path("/temp_voice")

# Create directories if they don't exist (RunPod deployment)
VOICE_PROFILES_DIR.mkdir(exist_ok=True)
VOICE_SAMPLES_DIR.mkdir(exist_ok=True)
TEMP_VOICE_DIR.mkdir(exist_ok=True)

logger.info(f"Using directories:")
logger.info(f"  VOICE_PROFILES_DIR: {VOICE_PROFILES_DIR}")
logger.info(f"  VOICE_SAMPLES_DIR: {VOICE_SAMPLES_DIR}")
logger.info(f"  TEMP_VOICE_DIR: {TEMP_VOICE_DIR}")

# Initialize Firebase storage client
storage_client = None
bucket = None

# Pre-load ChatterboxTTS model at module level (avoids re-initialization)
logger.info("üîß Pre-loading ChatterboxTTS model...")
try:
    from chatterbox.tts import ChatterboxTTS
    model = ChatterboxTTS.from_pretrained(device='cuda')
    logger.info("‚úÖ ChatterboxTTS model pre-loaded successfully")
    
    # Initialize the forked repository handler if available
    if FORKED_HANDLER_AVAILABLE:
        logger.info("üîß Pre-loading ChatterboxVC...")
        try:
            from chatterbox.vc import ChatterboxVC
            forked_handler = ChatterboxVC(
                s3gen=model.s3gen,
                device=model.device
            )
            logger.info("‚úÖ ChatterboxVC pre-loaded successfully")
        except Exception as e:
            logger.error(f"‚ùå Failed to pre-load ChatterboxVC: {e}")
            forked_handler = None
    else:
        logger.warning("‚ö†Ô∏è ChatterboxVC not available - will use fallback methods")
        forked_handler = None
    
    # Attach the T3 text‚Äëto‚Äëtoken encoder to S3Gen
    if hasattr(model, "s3gen") and hasattr(model, "t3"):
        model.s3gen.text_encoder = model.t3
        logger.info("üìå Attached text_encoder to model.s3gen")
        
except Exception as e:
    logger.error(f"‚ùå Failed to pre-load ChatterboxTTS model: {e}")
    model = None
    forked_handler = None

# -------------------------------------------------------------------
# üéµ MP3 Conversion Utilities
# -------------------------------------------------------------------
def tensor_to_mp3_bytes(audio_tensor, sample_rate, bitrate="96k"):
    """
    Convert audio tensor directly to MP3 bytes.
    
    :param audio_tensor: PyTorch audio tensor
    :param sample_rate: Audio sample rate
    :param bitrate: MP3 bitrate (e.g., "96k", "128k", "160k")
    :return: MP3 bytes
    """
    try:
        from pydub import AudioSegment
        # Convert tensor to AudioSegment
        audio_segment = tensor_to_audiosegment(audio_tensor, sample_rate)
        # Export to MP3 bytes
        mp3_file = audio_segment.export(format="mp3", bitrate=bitrate)
        # Read the bytes from the file object
        mp3_bytes = mp3_file.read()
        return mp3_bytes
    except ImportError:
        logger.warning("pydub not available, falling back to WAV")
        return tensor_to_wav_bytes(audio_tensor, sample_rate)
    except Exception as e:
        logger.warning(f"Direct MP3 conversion failed: {e}, falling back to WAV")
        return tensor_to_wav_bytes(audio_tensor, sample_rate)

def tensor_to_audiosegment(audio_tensor, sample_rate):
    """
    Convert PyTorch audio tensor to pydub AudioSegment.
    
    :param audio_tensor: PyTorch audio tensor
    :param sample_rate: Audio sample rate
    :return: pydub AudioSegment
    """
    from pydub import AudioSegment
    
    # Convert tensor to numpy array
    if audio_tensor.dim() == 2:
        # Stereo: (channels, samples)
        audio_np = audio_tensor.numpy()
    else:
        # Mono: (samples,) -> (1, samples)
        audio_np = audio_tensor.unsqueeze(0).numpy()
    
    # Convert to int16 for pydub
    audio_np = (audio_np * 32767).astype(np.int16)
    
    # Create AudioSegment
    audio_segment = AudioSegment(
        audio_np.tobytes(),
        frame_rate=sample_rate,
        sample_width=2,  # 16-bit
        channels=audio_np.shape[0]
    )
    
    return audio_segment

def tensor_to_wav_bytes(audio_tensor, sample_rate):
    """
    Convert audio tensor to WAV bytes (fallback).
    
    :param audio_tensor: PyTorch audio tensor
    :param sample_rate: Audio sample rate
    :return: WAV bytes
    """
    # Save to temporary WAV file
    temp_wav = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
    torchaudio.save(temp_wav.name, audio_tensor, sample_rate)
    
    # Read WAV bytes
    with open(temp_wav.name, 'rb') as f:
        wav_bytes = f.read()
    
    # Clean up temp file
    os.unlink(temp_wav.name)
    
    return wav_bytes

def convert_audio_file_to_mp3(input_path, output_path, bitrate="160k"):
    """
    Convert audio file to MP3 with specified bitrate.
    
    :param input_path: Path to input audio file
    :param output_path: Path to output MP3 file
    :param bitrate: MP3 bitrate
    """
    try:
        from pydub import AudioSegment
        # Load audio file
        audio = AudioSegment.from_file(input_path)
        # Export as MP3
        audio.export(output_path, format="mp3", bitrate=bitrate)
        logger.info(f"‚úÖ Converted {input_path} to MP3: {output_path}")
    except ImportError:
        raise ImportError("pydub is required for audio conversion")
    except Exception as e:
        logger.error(f"‚ùå Failed to convert {input_path} to MP3: {e}")
        raise

# -------------------------------------------------------------------
# üêû  Firebase / GCS credential debug helper
# -------------------------------------------------------------------
def _debug_gcs_creds():
    """Minimal Firebase credential check - removed extensive debugging since voice cloning is working"""
    import os
    logger.info("üîç Firebase credentials check")
    
    # Check if RunPod secret is available
    firebase_secret_path = os.getenv('RUNPOD_SECRET_Firebase')
    if firebase_secret_path:
        if firebase_secret_path.startswith('{'):
            logger.info("‚úÖ Using RunPod Firebase secret (JSON content)")
        else:
            logger.info("‚úÖ Using RunPod Firebase secret (file path)")
    else:
        logger.warning("‚ö†Ô∏è No RunPod Firebase secret found")

def initialize_firebase():
    """Initialize Firebase storage client"""
    global storage_client, bucket
    
    # Firebase initialization
    
    try:
        # Debug: Check environment variables
        logger.info("üîç Checking Firebase environment variables...")
        firebase_secret = os.getenv('RUNPOD_SECRET_Firebase')
        google_creds = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
        logger.info(f"üîç RUNPOD_SECRET_Firebase exists: {firebase_secret is not None}")
        logger.info(f"üîç GOOGLE_APPLICATION_CREDENTIALS exists: {google_creds is not None}")
        
        # Check if we're in RunPod and have the secret
        firebase_secret_path = os.getenv('RUNPOD_SECRET_Firebase')
        
        if firebase_secret_path:
            if firebase_secret_path.startswith('{'):
                # It's JSON content, create a temporary file
                logger.info("‚úÖ Using RunPod Firebase secret as JSON content")
                import tempfile
                import json
                
                # Validate JSON first
                try:
                    creds_data = json.loads(firebase_secret_path)
                    logger.info(f"‚úÖ Valid JSON with project_id: {creds_data.get('project_id', 'unknown')}")
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå Invalid JSON in RUNPOD_SECRET_Firebase: {e}")
                    raise
                
                # Create temporary file with the JSON content
                with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp_file:
                    json.dump(creds_data, tmp_file)
                    tmp_path = tmp_file.name
                
                logger.info(f"‚úÖ Created temporary credentials file: {tmp_path}")
                storage_client = storage.Client.from_service_account_json(tmp_path)
                
            elif os.path.exists(firebase_secret_path):
                # It's a file path
                logger.info(f"‚úÖ Using RunPod Firebase secret file: {firebase_secret_path}")
                storage_client = storage.Client.from_service_account_json(firebase_secret_path)
            else:
                logger.warning(f"‚ö†Ô∏è RUNPOD_SECRET_Firebase exists but is not JSON content or valid file path")
                # Fallback to GOOGLE_APPLICATION_CREDENTIALS
                logger.info("üîÑ Using GOOGLE_APPLICATION_CREDENTIALS fallback")
                storage_client = storage.Client()
        else:
            # No RunPod secret, fallback to GOOGLE_APPLICATION_CREDENTIALS
            logger.info("üîÑ Using GOOGLE_APPLICATION_CREDENTIALS fallback")
            storage_client = storage.Client()
        
        bucket = storage_client.bucket("godnathistorie-a25fa.firebasestorage.app")
        logger.info("‚úÖ Firebase storage client initialized successfully")
        return True
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize Firebase storage: {e}")
        return False

def upload_to_firebase(data: bytes, destination_blob_name: str, content_type: str = "application/octet-stream", metadata: dict = None) -> Optional[str]:
    """
    Upload data directly to Firebase Storage with metadata
    
    :param data: Binary data to upload
    :param destination_blob_name: Destination path in Firebase
    :param content_type: MIME type of the file
    :param metadata: Optional metadata to store with the file
    :return: Public URL or None if failed
    """
    global bucket # Ensure bucket is accessible
    if bucket is None:
        logger.info("üîç Bucket is None, initializing Firebase...")
        if not initialize_firebase():
            logger.error("‚ùå Firebase not initialized, cannot upload")
            return None
    
    try:
        logger.info(f"üîç Creating blob: {destination_blob_name}")
        blob = bucket.blob(destination_blob_name)
        logger.info(f"üîç Uploading {len(data)} bytes...")
        
        # Set metadata if provided
        if metadata:
            blob.metadata = metadata
            logger.info(f"üîç Set metadata: {metadata}")
        
        # Set content type
        blob.content_type = content_type
        logger.info(f"üîç Set content type: {content_type}")
        
        # Upload the data
        blob.upload_from_string(data, content_type=content_type)
        logger.info(f"üîç Upload completed, making public...")
        
        # Make the blob publicly accessible
        blob.make_public()
        
        public_url = blob.public_url
        logger.info(f"‚úÖ Uploaded to Firebase: {destination_blob_name} -> {public_url}")
        return public_url
        
    except Exception as e:
        logger.error(f"‚ùå Firebase upload failed: {e}")
        return None

def get_voice_id(name):
    """Generate a unique ID for a voice based on the name"""
    # Create a clean, filesystem-safe voice ID from the name
    import re
    clean_name = re.sub(r'[^a-zA-Z0-9_-]', '', name.lower().replace(' ', '_'))
    return f"voice_{clean_name}"

def list_files_for_debug():
    """List files in our directories for debugging"""
    logger.info("üìÇ Directory contents:")
    for directory in [VOICE_PROFILES_DIR, VOICE_SAMPLES_DIR, TEMP_VOICE_DIR]:
        if directory.exists():
            files = list(directory.glob("*"))
            logger.info(f"  {directory}: {[f.name for f in files]} ({len(files)} files)")
        else:
            logger.info(f"  {directory}: [DIRECTORY NOT FOUND]")
            
def generate_template_message(name):
    """Generate the template message for the voice clone"""
    return f"Hello, this is the voice clone of {name}. This voice is used to narrate whimsical stories and fairytales."

def save_voice_profile(temp_voice_file, voice_id):
    """Save voice profile directly to target location"""
    global model, forked_handler
    
    # Get final profile path
    profile_path = VOICE_PROFILES_DIR / f"{voice_id}.npy"
    logger.info(f"üíæ Saving voice profile directly to: {profile_path}")
    
    # Check if profile already exists
    if profile_path.exists():
        logger.info(f"‚úÖ Voice profile already exists for {voice_id}")
        return profile_path
    
    try:
        # Use forked repository handler if available
        if forked_handler is not None and hasattr(forked_handler, 'set_target_voice'):
            logger.info(f"üìÅ Using forked repository ChatterboxVC.set_target_voice method")
            # ChatterboxVC doesn't have a save_voice_profile method, so we'll use the model method
            if hasattr(model, 'save_voice_profile'):
                model.save_voice_profile(str(temp_voice_file), str(profile_path))
                logger.info(f"‚úÖ Voice profile saved using model method to: {profile_path}")
            else:
                logger.warning(f"‚ö†Ô∏è Model doesn't have save_voice_profile method")
        elif hasattr(model, 'save_voice_profile'):
            logger.info(f"üìÅ Using enhanced save_voice_profile method")
            
            # Pass the audio file path directly (not the loaded tensor)
            logger.info(f"üéµ Using audio file: {temp_voice_file}")
            
            # Save profile using file path
            model.save_voice_profile(str(temp_voice_file), str(profile_path))
            logger.info(f"‚úÖ Voice profile saved directly to: {profile_path}")
        else:
            # Fallback: create a placeholder 
            logger.warning(f"Enhanced profile saving not available, creating placeholder for {voice_id}")
            with open(profile_path, 'w') as f:
                f.write(f"voice_id: {voice_id}")
            logger.info(f"üìù Created placeholder: {profile_path}")
            
        # Verify the file was created
        if profile_path.exists():
            file_size = profile_path.stat().st_size
            logger.info(f"‚úÖ Verified profile file: {profile_path} ({file_size} bytes)")
        else:
            logger.error(f"‚ùå Profile file not created: {profile_path}")
                
        return profile_path
        
    except Exception as e:
        logger.error(f"Failed to save voice profile: {e}")
        raise

def load_voice_profile(voice_id):
    """Load existing voice profile"""
    global model, forked_handler
    
    # Get profile path
    profile_path = VOICE_PROFILES_DIR / f"{voice_id}.npy"
    logger.info(f"üîç Loading voice profile from: {profile_path}")
    
    if not profile_path.exists():
        raise FileNotFoundError(f"No voice profile found for {voice_id}")
    
    try:
        # Use forked repository handler if available
        if forked_handler is not None and hasattr(forked_handler, 'set_target_voice'):
            logger.info(f"üìÅ Using forked repository ChatterboxVC - will set target voice from profile")
            # ChatterboxVC doesn't have a load_voice_profile method, so we'll use the model method
            if hasattr(model, 'load_voice_profile'):
                profile = model.load_voice_profile(str(profile_path))
                logger.info(f"‚úÖ Loaded voice profile using model method from {profile_path}")
                return profile
            else:
                logger.warning(f"‚ö†Ô∏è Model doesn't have load_voice_profile method")
        elif hasattr(model, 'load_voice_profile'):
            # Use enhanced method from forked repository
            profile = model.load_voice_profile(str(profile_path))
            logger.info(f"‚úÖ Loaded voice profile from {profile_path}")
            return profile
        else:
            # Fallback: return None to indicate we should use the original audio file method
            logger.warning(f"Enhanced profile loading not available, will use original audio file method for {voice_id}")
            return None
        
    except Exception as e:
        logger.error(f"Failed to load voice profile: {e}")
        raise

def handler(event, responseFormat="base64"):
    input = event['input']    
    
    # This handler is for voice cloning only
    return handle_voice_clone_request(input, responseFormat)

def handle_voice_clone_request(input, responseFormat):
    """Handle voice cloning requests"""
    global forked_handler
    
    # Initialize Firebase at the start
    if not initialize_firebase():
        logger.error("‚ùå Failed to initialize Firebase, cannot proceed")
        return {"status": "error", "message": "Failed to initialize Firebase storage"}
    
    # Check if model is pre-loaded
    global model
    if model is None:
        logger.error("‚ùå ChatterboxTTS model not pre-loaded")
        return {"status": "error", "message": "ChatterboxTTS model not available"}
    
    logger.info("‚úÖ Using pre-loaded ChatterboxTTS model")
    
    # Handle voice generation request only
    name = input.get('name')
    audio_data = input.get('audio_data')  # Base64 encoded audio data
    audio_format = input.get('audio_format', 'wav')  # Format of the input audio
    responseFormat = input.get('responseFormat', 'base64')  # Response format from frontend
    language = input.get('language', 'en')  # Language for storage organization
    is_kids_voice = input.get('is_kids_voice', False)  # Kids voice flag

    if not name or not audio_data:
        return {"status": "error", "message": "Both name and audio_data are required"}

    logger.info(f"New request. Voice clone name: {name}")
    logger.info(f"Response format requested: {responseFormat}")
    logger.info(f"Language: {language}, Kids voice: {is_kids_voice}")
    
    # Generate the template message
    template_message = generate_template_message(name)
    logger.info(f"Generated template message: {template_message}")
    
    try:
        # Generate a unique voice ID based on the name
        voice_id = get_voice_id(name)
        logger.info(f"Generated voice ID: {voice_id}")
        
        # Save the uploaded audio to temp directory for embedding extraction
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        temp_voice_file = TEMP_VOICE_DIR / f"{voice_id}_{timestamp}.{audio_format}"
        audio_bytes = base64.b64decode(audio_data)  # Still need this for now since FastAPI sends base64
        with open(temp_voice_file, 'wb') as f:
            f.write(audio_bytes)
        logger.info(f"Saved temporary voice file to {temp_voice_file}")

        # Step 1: Create voice profile (keep original quality)
        profile_path = VOICE_PROFILES_DIR / f"{voice_id}.npy"
        if profile_path.exists():
            logger.info(f"üéµ Loading existing profile: {voice_id}")
            profile = load_voice_profile(voice_id)
        else:
            logger.info(f"üéµ Creating new profile: {voice_id}")
            save_voice_profile(temp_voice_file, voice_id)
            profile = load_voice_profile(voice_id)
        
        # Step 2: Convert and save recorded audio (160 kbps MP3)
        recorded_audio_path = None
        try:
            # Convert original recording to 160 kbps MP3
            temp_mp3_file = TEMP_VOICE_DIR / f"{voice_id}_{timestamp}_recorded.mp3"
            convert_audio_file_to_mp3(str(temp_voice_file), str(temp_mp3_file), "160k")
            
            # Upload recorded audio to Firebase
            with open(temp_mp3_file, 'rb') as f:
                recorded_mp3_bytes = f.read()
            
            if is_kids_voice:
                recorded_firebase_path = f"audio/voices/{language}/kids/recorded/{voice_id}_{timestamp}.mp3"
            else:
                recorded_firebase_path = f"audio/voices/{language}/recorded/{voice_id}_{timestamp}.mp3"
            
            # Store metadata with the recorded audio file
            recorded_metadata = {
                'voice_id': voice_id,
                'voice_name': name,
                'file_type': 'recorded_audio',
                'language': language,
                'is_kids_voice': str(is_kids_voice),
                'format': '160k_mp3',
                'timestamp': timestamp,
                'created_date': datetime.now().isoformat(),
                'model': 'chatterbox_tts',
                'Access-Control-Allow-Origin': '*',
                'Cache-Control': 'public, max-age=3600'
            }
            
            recorded_uploaded = upload_to_firebase(
                recorded_mp3_bytes,
                recorded_firebase_path,
                "audio/mpeg",
                recorded_metadata
            )
            if recorded_uploaded:
                recorded_audio_path = recorded_firebase_path
                logger.info(f"üéµ Recorded audio uploaded: {recorded_firebase_path}")
            
            # Clean up temp MP3 file
            os.unlink(temp_mp3_file)
            
        except Exception as e:
            logger.error(f"‚ùå Failed to convert/upload recorded audio: {e}")
        
        # Track which generation method was used
        generation_method = "unknown"
        
        # Step 3: Generate voice sample (96 kbps MP3)
        audio_tensor = None
        if profile is not None:
            # Use profile-based generation (forked repository method)
            logger.info("üîÑ Using profile-based generation")
            generation_method = "profile_based"
            
            # Use the correct high-level method: ChatterboxTTS.generate() with voice_profile_path
            logger.info("üîç Using standard ChatterboxTTS.generate() with voice_profile_path")
            try:
                # Use the saved voice profile file directly
                profile_path_str = str(profile_path)
                logger.info(f"üéµ Using voice profile: {profile_path_str}")
                
                audio_tensor = model.generate(
                    text=template_message,
                    voice_profile_path=profile_path_str,  # ‚úÖ Correct parameter name
                    temperature=0.8,
                    exaggeration=0.5,
                    cfg_weight=0.5
                )
                generation_method = "standard_generate_with_voice_profile"
                logger.info("‚úÖ Used standard ChatterboxTTS.generate() with voice_profile_path")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Standard generate with voice_profile_path failed: {e}")
                logger.warning(f"‚ö†Ô∏è Exception type: {type(e).__name__}")
                
                # Fallback: Use original audio file method
                logger.warning("‚ö†Ô∏è Falling back to audio_prompt_path method")
                audio_tensor = model.generate(
                    text=template_message,
                    audio_prompt_path=str(temp_voice_file),
                    temperature=0.8
                )
                generation_method = "fallback_audio_prompt"
                logger.info("‚úÖ Used fallback audio_prompt_path method")
        else:
            # Use original audio file method (fallback)
            logger.info("üîÑ Using audio file method")
            logger.info(f"üîß Model is: {model}")
            logger.info(f"üîß Model type: {type(model)}")
            if model is None:
                raise RuntimeError("Model is None - initialization failed")
            audio_tensor = model.generate(template_message, audio_prompt_path=str(temp_voice_file))
            generation_method = "audio_file"

        # Convert audio tensor to MP3 bytes (96 kbps)
        sample_mp3_bytes = tensor_to_mp3_bytes(audio_tensor, model.sr, "96k")
        logger.info(f"üéµ Generated voice sample in MP3 format: {len(sample_mp3_bytes)} bytes")
        
        # Upload voice sample to Firebase
        sample_audio_path = None
        try:
            if is_kids_voice:
                sample_firebase_path = f"audio/voices/{language}/kids/samples/{voice_id}_sample_{timestamp}.mp3"
            else:
                sample_firebase_path = f"audio/voices/{language}/samples/{voice_id}_sample_{timestamp}.mp3"
            
            # Store metadata with the voice sample file
            sample_metadata = {
                'voice_id': voice_id,
                'voice_name': name,
                'file_type': 'voice_sample',
                'language': language,
                'is_kids_voice': str(is_kids_voice),
                'format': '96k_mp3',
                'timestamp': timestamp,
                'created_date': datetime.now().isoformat(),
                'generation_method': generation_method,
                'model': 'chatterbox_tts',
                'Access-Control-Allow-Origin': '*',
                'Cache-Control': 'public, max-age=3600'
            }
            
            sample_uploaded = upload_to_firebase(
                sample_mp3_bytes,
                sample_firebase_path,
                "audio/mpeg",
                sample_metadata
            )
            if sample_uploaded:
                sample_audio_path = sample_firebase_path
                logger.info(f"üéµ Voice sample uploaded: {sample_firebase_path}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to upload voice sample: {e}")

        # Clean up temporary voice file
        try:
            os.unlink(temp_voice_file)
        except Exception as cleanup_error:
            logger.warning(f"‚ö†Ô∏è Failed to clean up temp file: {cleanup_error}")

    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}")
        if 'temp_voice_file' in locals():
            try:
                os.unlink(temp_voice_file)
            except:
                pass
        return {"status": "error", "message": str(e)}

    # Upload voice profile to Firebase
    profile_path_firebase = None
    if profile_path.exists():
        try:
            with open(profile_path, 'rb') as f:
                profile_data = f.read()
            
            if is_kids_voice:
                profile_firebase_path = f"audio/voices/{language}/kids/profiles/{voice_id}.npy"
            else:
                profile_firebase_path = f"audio/voices/{language}/profiles/{voice_id}.npy"
            
            # Store metadata with the voice profile file
            profile_metadata = {
                'voice_id': voice_id,
                'voice_name': name,
                'file_type': 'voice_profile',
                'language': language,
                'is_kids_voice': str(is_kids_voice),
                'format': 'npy',
                'created_date': datetime.now().isoformat(),
                'model': 'chatterbox_tts',
                'Access-Control-Allow-Origin': '*',
                'Cache-Control': 'public, max-age=3600'
            }
            
            profile_uploaded = upload_to_firebase(
                profile_data,
                profile_firebase_path,
                "application/octet-stream",
                profile_metadata
            )
            if profile_uploaded:
                profile_path_firebase = profile_firebase_path
                logger.info(f"üì¶ Profile uploaded: {profile_firebase_path}")
        except Exception as e:
            logger.error(f"Failed to upload profile file: {e}")
    else:
        logger.error(f"‚ùå Profile file does not exist: {profile_path}")

    # Log final summary (minimal)
    logger.info(f"üéØ Generation method: {generation_method}")
    logger.info(f"üì¶ Profile uploaded: {'YES' if profile_path_firebase else 'NO'}")
    logger.info(f"üéµ Recorded audio uploaded: {'YES' if recorded_audio_path else 'NO'}")
    logger.info(f"üéµ Voice sample uploaded: {'YES' if sample_audio_path else 'NO'}")
    
    # Return response (compatible with Higgs Audio format)
    response = {
        "status": "success",
        "voice_id": voice_id,
        "profile_path": profile_path_firebase,
        "sample_path": sample_audio_path,
        "recorded_path": recorded_audio_path,
        "profile_url": profile_path_firebase,  # Use path as URL for compatibility
        "sample_url": sample_audio_path,  # Use path as URL for compatibility
        "recorded_url": recorded_audio_path,  # Use path as URL for compatibility
        "generation_time": time.time() - start_time if 'start_time' in locals() else 0,
        "model": "chatterbox_tts",
        # Add Higgs Audio compatibility fields
        "sample_audio_path": sample_audio_path,
        "embedding_path": profile_path_firebase,
        "voice_name": name,
        "created_date": int(time.time()),
        # Keep original metadata for debugging
        "metadata": {
            "sample_rate": model.sr,
            "audio_shape": list(audio_tensor.shape) if audio_tensor is not None else None,
            "voice_id": voice_id,
            "voice_name": name,
            "profile_path_local": str(profile_path),
            "profile_exists": profile_path.exists(),
            "has_profile_support": hasattr(model, 'save_voice_profile') and hasattr(model, 'load_voice_profile'),
            "generation_method": generation_method,
            "template_message": template_message,
            "forked_handler_used": forked_handler is not None,
            "language": language,
            "is_kids_voice": is_kids_voice,
            "recorded_format": "160k_mp3",
            "sample_format": "96k_mp3"
        }
    }
    logger.info(f"üì§ Voice clone completed successfully")
    return response 



if __name__ == '__main__':
    logger.info("üöÄ Voice Clone Handler starting...")
    initialize_model()
    logger.info("‚úÖ Voice Clone Handler ready")
    runpod.serverless.start({'handler': handler })
