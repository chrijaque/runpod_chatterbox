FROM runpod/pytorch:2.8.0-py3.11-cuda12.8.1-cudnn-devel-ubuntu22.04

ENV PYTHONUNBUFFERED=1
ENV DEBIAN_FRONTEND=noninteractive

# Install system dependencies including FFmpeg
RUN apt-get update && \
    apt-get install -y \
    git \
    wget \
    curl \
    ffmpeg \
    libavcodec-extra \
    libavformat-dev \
    libavutil-dev \
    libswscale-dev && \
    rm -rf /var/lib/apt/lists/*

# Set git global config to avoid warnings
RUN git config --global --add safe.directory '*'

# Copy requirements first for better caching
COPY requirements/chatterbox.txt /requirements.txt

# Cache-bust arg so we can force refresh clone layer during tests.
ARG RUNPOD_CACHE_BUST=dev
RUN echo "RUNPOD_CACHE_BUST=${RUNPOD_CACHE_BUST}"

# Clone the repository
RUN git clone https://github.com/chrijaque/chatterbox_embed.git /workspace/chatterbox_embed

# Install chatterbox_embed in editable mode without dependencies
RUN cd /workspace/chatterbox_embed && pip install -e /workspace/chatterbox_embed --no-deps

# Firestore for TTS story update writes (stories/{story_id})
RUN pip install google-cloud-firestore>=2.13.0

# Install dependencies from requirements.txt, excluding torch and torchaudio (already in base image)
RUN cd /workspace/chatterbox_embed && \
    grep -v "^torch" requirements.txt | grep -v "^torchaudio" > /tmp/filtered_requirements.txt && \
    pip install -r /tmp/filtered_requirements.txt || \
    pip install numpy>=1.26.0 librosa==0.11.0 s3tokenizer transformers==4.46.3 diffusers==0.29.0 resemble-perth==1.0.1 conformer==0.3.2 safetensors==0.5.3 tqdm einops scipy soundfile audioread huggingface_hub tokenizers accelerate setuptools>=61.0 importlib-metadata typing_extensions packaging inflect

# Install torchvision compatible with PyTorch 2.8.0 (from base image, not downgraded)
RUN pip install torchvision --index-url https://download.pytorch.org/whl/cu121

# Verify versions
RUN python -c "import torch; print(f'PyTorch: {torch.__version__}')"

# Pre-download models from HuggingFace to the default cache location
# This allows from_pretrained() to find cached models without downloading
# Set up HuggingFace cache directories
ENV HF_HOME=/models/hf
ENV HF_HUB_CACHE=/models/hf/hub
ENV TRANSFORMERS_CACHE=/models/hf
RUN mkdir -p "$HF_HOME" "$HF_HUB_CACHE" "$TRANSFORMERS_CACHE"

# Pre-download models to HuggingFace cache (same location VC uses)
RUN python - <<'PY'
import sys
from huggingface_hub import snapshot_download
import os
try:
    cache_dir = os.getenv("HF_HOME", "/models/hf")
    print(f"ðŸ”½ Pre-downloading ResembleAI/chatterbox models to {cache_dir}...")
    snapshot_download(
        repo_id="ResembleAI/chatterbox",
        revision="main",
        cache_dir=cache_dir,
    )
    print("âœ… Models pre-downloaded successfully to HuggingFace cache")
except Exception as e:
    print(f"âŒ Pre-download failed: {e}")
    print("ðŸ’¡ Models must be downloaded during Docker build")
    sys.exit(1)  # Fail the build if download fails
PY

# Skip chatterbox import test - will work at runtime
RUN pip show chatterbox-tts || echo "Package check skipped"

# Step 5: Install RunPod SDK
RUN pip install runpod>=1.5.0

# Copy TTS handler script
COPY handlers/chatterbox/tts_handler.py /handler.py

# Set working directory
WORKDIR /

# Set the entrypoint to the TTS handler
CMD ["python3", "-u", "handler.py"]
